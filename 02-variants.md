---
title: "Hands-on Variant Analysis in Galaxy and IGV"
author: "Mark Dunning"
output:
  html_notebook:
    toc: yes
    toc_float: yes
    css: stylesheets/styles.css
  html_document:
    df_print: paged
    toc: yes
editor_options:
  chunk_output_type: inline
---

### Sheffield Bioinformatics Core
<img src="media/logo-sm.png" align=right>

web : [sbc.shef.ac.uk](http://sbc.shef.ac.uk)  
twitter: [SheffBioinfCore](https://twitter.com/SheffBioinfCore)  
email: [bioinformatics-core@sheffield.ac.uk](bioinformatics-core@sheffield.ac.uk)

-----

# Tutorial Overview

This tutorial will cover the basics of variant-calling using Galaxy; a open-source web-based platform for the analysis of biological data. You should gain an appreciation of the tasks involved in a typical NGS analysis and be comfortable with the outputs generated by a sequencing service. You will also use the Integrative Genomics Viewer (IGV) to *view* the aligned reads in an interactive manner.

We will use training materials provided by the Galaxy Project and sign-post to relevant sections. If you want to find more detailed tutorials on IGV or Galaxy you can follow the links below:-

- [Galaxy Training Portal](https://training.galaxyproject.org/training-material/)
- [IGV Tutorial](https://github.com/griffithlab/rnaseq_tutorial/wiki/IGV-Tutorial)


<img src="media/germline_vs_somatic.PNG"/>

# Preparation and Data Upload

If attending this workshop in-person you should have access to a private queue on the usegalaxy.eu server that will allow your jobs to run quicker.

Follow this link on December 1st to join the queue 

https://usegalaxy.eu/join-training/sbcgalaxy-2021-12-01

## Import the *Germline* data for the workshop.

We are using data from a *trio* of individuals that have been downsampled to be used in various Galaxy tutorials:-

- https://zenodo.org/record/60520#.YYkrqtbP3xo

Download all the files ending in `.bam` to your laptop

You can import the data by:

1.  In the tool panel located on the left, select **Get
    Data > Upload File**. 
2.  **Choose local file** and browse to the directory containing the files from the google drive and select all the file. Click **Open** to close the file browser. The names of the files should now appear in Galaxy.
3.  Click **Start** to begin the upload

3.  You should now have these 3 files in your history:

- `mother.bam`
- `father.bam`
- `patient.bam`

<div class="exercise">

**Question**: What is the primary purpose of the `.bam` file? What Bioinformatics processes / tools have already been performed on the data?

</div>

## Set the genome build

As we didn't align these data in Galaxy, we don't automatically have a record of which reference genome was used. This may cause problems downstream. You can specify a genome build by using the pencil icon next to the names of the `bam` files in your history and choosing hg19 from the **Database/Build** drop-down.

<img src="media/genome_build.PNG"/>


## Quality control

As with other types of high-throughput data, we should perform a quality assessment to check that the data are suitable for further processing. Here is a summary of some of the tools we could use:-

### fastQC

<div class="information">

FASTA/FASTQ -> **FastQC** Read Quality reports

</div>


We have already used this tool in the Introduction to NGS session. It will provide a quality assessment on the base-calls of our sequencing. It does not use any information about the alignment, but can still be run on `.bam` files due to the raw sequences being present in the `.bam` file.


### idxstats

<div class="information">

SAM/BAM -> **Samtools idxstats** reports stats of the BAM index file

</div>


This QC tool will report how many reads aligned to each of the reference chromosomes in a reference genome. It is part of the `samtools` suite of tools.


### samtools flagstat

<div class="information">

SAM/BAM -> **Samtools flagstat** tabulate descriptive stats for BAM dataset

</div>


This tools extracts the "flag" data contained in the `.bam` file and tabulates the results. The flag is used to encode various properties of reads such as being a PCR duplicate, being un-mapped, or having a paired read within an expected insert distance.

### Combined QC report with multiqc

The multiQC tool that we have seen previously can be used to 

<div class="exercise">

**Exercise**: Inspect the `.bam` files, and use the output of the QC tools to answer the following questions:-

- Which tool was used to align the reads?
- What chromosome have the reads been aligned to?
- Are the data single- or paired-end?
- Has a tool been run to mark duplicates?

</div>



## Viewing the alignments

If we are reasonably happy with the QC, the next step would be to inspect the data visually. As we have seen in the previous session, IGV is a very convenient tool for this. 

<img src="media/IGV_trio.PNG"/>

<div class="exercise">

**Exercise:** Load the input bam files into IGV. The first time you try and do this, it should give an error about an "index" file missing. Which file is it missing? See the IGVtools option under the Tools menu of IGV and see if you can generate the missing files.

**Make sure to set hg19 as your reference genome**. Once the files are loaded, navigate to `chr22` and zoom until you start to see reads. The data are supposed be from an exome sequencing experiment. Does it looks like exons have been sequenced? What differences might you see in whole-genome data?

</div>

# Post-processing of reads and Variant Calling

We will now go through a series of steps to produce a set of variant-calls ready for further interpretation.

## Mark Duplicates with Picard

As we have seen, it does not appear the duplicates have been identified in the data. This is commonly-done using the `Picard` suite of tools.


<div class="information">

Picard -> **MarkDuplicates** examine aligned records in BAM datasets to locate duplicate molecules

</div>

- Select the `father.bam`, `mother.bam` and `patient.bam` files in the **Select SAM/BAM dataset or dataset collection**. Don't forget to can select multiple bam files using the multiple datasets button.
- No other options need to be changed

It is recommended that you rename the BAM outputs so that you can keep track of your analysis; for example `patient_duplicates.bam`, `father_duplicates.bam` and `mother_duplicates.bam`.


## Call variants with `Freebayes`

We will call variants in our trio of samples using the `FreeBayes` tool. As it's name implies, this is a method based on computing Bayesian probabilities. A more-detailed explanation is provided in [this Galaxy tutorial](https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/dip/tutorial.html).

The required parameters for freebayes are given below. Notice that we restrict the analysis to just chromosome 22.

<div class="information">

Variant Calling -> **FreeBayes** bayesian genetic variant detector

</div>

- **Choose the source for the reference genome** Locally cached
- Select Run individually in **Run in batch mode**
- Under **Bam dataset** select the three bam files with **duplicates marked**
- **Using reference genome** Human (Homo sapiens): hg19
- **Limit variant calling to a set of regions?** Limit to region
  - **Region Chromosome**: chr22
  - **Region Start**: 1
  - **Region End**: 51304566
- **Read coverage**: Use defaults
- **Choose parameter selection level** 1. Simple diploid calling

<div class="warning">
If you didn't set the genome build for the bam files, the tool may refuse to run. Use the pencil icon next to the bam files to edit and specify hg19 as the genome build (see above for screenshot).
</div>

Again, it would be good to rename these outputs to something more memorable; e.g. `father.vcf`, `mother.vcf` and `patient.vcf`. We will now explore the files we have just created.

## About vcf format


In the previous section, you will have produced a *vcf* file. The `.vcf` format was initially developed by the [1000 Genomes Project](http://www.1000genomes.org/wiki/Analysis/vcf4.0), and ownership has been subsequently transferred to [Global Alliance for Genomics and Health Data Working group file format team](http://ga4gh.org/#/fileformats-team). The format can be used to represent information about all kinds of genomic variation. In this session we will just consider SNVs.

We donâ€™t require any specialised software to look at the contents of a vcf file. They can be opened in a bog-standard text editor, however your laptop may try and interpret the file as containing contact information (virtual contact file).

In a similar vein to the `.bam` and `.sam` files we saw earlier, the `.vcf` files contains many lines of header information. These describe the reference sequences and information on how the variant calls and genotypes are represented.

It may ease the interpretation of these new files by running the following tool to convert them into a tab-delimited file

<div class="information">
Variant Calling -> **VCFtoTab-delimited** Convert VCF data to TAB delimited format
</div>

```
##fileformat=VCFv4.2
##fileDate=20211109
##source=freeBayes v1.3.1-dirty
##reference=/data/db/reference_genomes/hg19/seq/hg19.fa
##contig=<ID=chr10,length=135534747>
......
......
##commandline="freebayes --region chr22:1..51304566 --bam b_0.bam --fasta-reference /data/db/reference_genomes/hg19/seq/hg19.fa --vcf ./vcf_output/part_chr22:1..51304566.vcf"
##INFO=<ID=NS,Number=1,Type=Integer,Description="Number of samples with data">
##INFO=<ID=DP,Number=1,Type=Integer,Description="Total read depth at the locus">
##INFO=<ID=DPB,Number=1,Type=Float,Description="Total read depth per bp at the locus; bases in reads overlapping / bases in haplotype">
##INFO=<ID=AC,Number=A,Type=Integer,Description="Total number of alternate alleles in called genotypes">
......
......
##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">
##FORMAT=<ID=GQ,Number=1,Type=Float,Description="Genotype Quality, the Phred-scaled marginal (or unconditional) probability of the called genotype">
##FORMAT=<ID=GL,Number=G,Type=Float,Description="Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy">
##FORMAT=<ID=DP,Number=1,Type=Integer,Description="Read Depth">

```

After many more lines of information, we finally get to the details of the actual calls themselves. This part of the file is tab-delimited; with 10 columns for every call. The vcf specification page gives details of what should be contained in each column


Shown here is the information about three calls

```
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	RS024V-FATHER
chr22	16123469	.	T	G	1.11972	.	AB=0;ABP=0;AC=2;AF=1;AN=2;AO=3;CIGAR=1X;DP=3;DPB=3;DPRA=0;EPP=3.73412;EPPR=0;GTI=0;LEN=1;MEANALT=1;MQM=2.66667;MQMR=0;NS=1;NUMALT=1;ODDS=1.22395;PAIRED=1;PAIREDR=0;PAO=0;PQA=0;PQR=0;PRO=0;QA=107;QR=0;RO=0;RPL=2;RPP=3.73412;RPPR=0;RPR=1;RUN=1;SAF=2;SAP=3.73412;SAR=1;SRF=0;SRP=0;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:AD:RO:QR:AO:QA:GL	1/1:3:0,3:0:0:3:107:-0.746352,-0.90309,0
chr22	16124819	.	T	C	42.5105	.	AB=0;ABP=0;AC=0;AF=0;AN=2;AO=4;CIGAR=1X;DP=21;DPB=21;DPRA=0;EPP=5.18177;EPPR=9.26925;GTI=0;LEN=1;MEANALT=1;MQM=1;MQMR=1;NS=1;NUMALT=1;ODDS=9.78835;PAIRED=0;PAIREDR=0.411765;PAO=0;PQA=0;PQR=0;PRO=0;QA=148;QR=586;RO=17;RPL=1;RPP=5.18177;RPPR=9.26925;RPR=3;RUN=1;SAF=4;SAP=11.6962;SAR=0;SRF=17;SRP=39.9253;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:AD:RO:QR:AO:QA:GL	0/0:21:17,4:17:586:4:148:0,-5.95171,-1.11016
chr22	16125108	.	A	T	10.7921	.	AB=0;ABP=0;AC=0;AF=0;AN=2;AO=2;CIGAR=1X;DP=7;DPB=7;DPRA=0;EPP=7.35324;EPPR=6.91895;GTI=0;LEN=1;MEANALT=1;MQM=1;MQMR=1;NS=1;NUMALT=1;ODDS=2.39796;PAIRED=0;PAIREDR=0.4;PAO=0;PQA=0;PQR=0;PRO=0;QA=74;QR=181;RO=5;RPL=2;RPP=7.35324;RPPR=6.91895;RPR=0;RUN=1;SAF=0;SAP=7.35324;SAR=2;SRF=0;SRP=13.8677;SRR=5;TYPE=snp;technology.ILLUMINA=1	GT:DP:AD:RO:QR:AO:QA:GL	0/0:7:5,2:5:181:2:74:0,-1.91725,-0.269908
```

The first seven columns should look consistent across different genotype callers and are the easiest to interpret. These columns tell you where `FreeBayes` has identified a possible variant, and which base(s) are present in the reference genome and the sample.

The contents of the `INFO` and `FORMAT` columns will depend on what variant caller has been used. The `INFO` column contains metrics and other information related to each variant call as a set of `KEY=VALUE` pairs. Each pair is separated by a `;` character.

The INFO for the a variant call may read as:-

```
AB=0;ABP=0;AC=2;AF=1;AN=2;AO=3;CIGAR=1X;DP=3
```

or 

```
      Key   Value
AB=0  AB  0
ABP=0 ABP 0
AC=2  AC  2
```
etc...

The meaning of each key can be discovered by looking at the header for the file. e.g. `##FORMAT=<ID=DP,Number=1,Type=Integer,Description="Read depth">`. So this variant has a total of 3 bases covering it. 


The column in the file describes the genotype calls for sample. In the sample column (`RS024V-FATHER`) for the first variant we see the entry

```
1/1:3:0,3:0:0:3:107:-0.746352,-0.90309,0
```

These are values separated by a `:` character and they are interpreted in the same order as dictated by the FORMAT column; which is `GT:DP:AD:RO:QR:AO:QA:GL`


```
##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">
##FORMAT=<ID=GQ,Number=1,Type=Float,Description="Genotype Quality, the Phred-scaled marginal (or unconditional) probability of the called genotype">
##FORMAT=<ID=GL,Number=G,Type=Float,Description="Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy">
##FORMAT=<ID=DP,Number=1,Type=Integer,Description="Read Depth">
##FORMAT=<ID=AD,Number=R,Type=Integer,Description="Number of observation for each allele">
##FORMAT=<ID=RO,Number=1,Type=Integer,Description="Reference allele observation count">
##FORMAT=<ID=QR,Number=1,Type=Integer,Description="Sum of quality of the reference observations">
##FORMAT=<ID=AO,Number=A,Type=Integer,Description="Alternate allele observation count">
##FORMAT=<ID=QA,Number=A,Type=Integer,Description="Sum of quality of the alternate observations">
```

So for this particular variant there is a genotype of `1\1` (Homozygous for the alternate allele) in the sample and a depth of `3` etc. 

## Refined variant-calling

For the current analysis we have one vcf output for each sample. An alternative analysis exists which will give a merged vcf as an output

- **Choose the source for the reference genome** Locally cached
- Select Merge output VCFs in **Run in batch mode**
- Under **Bam dataset** select the three bam files with **duplicates marked**
- **Using reference genome** Human (Homo sapiens): hg19
- **Limit variant calling to a set of regions?** Limit to region
  - **Region Chromosome**: chr22
  - **Region Start**: 1
  - **Region End**: 51304566
- **Read coverage**: Use defaults
- **Choose parameter selection level** 1. Simple diploid calling

## SnpSift Filter

- `DP > 10`
- `QUAL > 100`
- `type=snp`

## Intersect with exon regions


# Annotation

## Annotating with SNPeff

As we have seen the standard vcf file contains genome coordinates for each variant, but gives no useful information about what gene (if any) the variant lies within or the potential impact of the variant. One such tool for adding genomic information is SNPeff which is described in the Galaxy tutorial.

- [See here](https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/somatic-variants/tutorial.html#adding-annotations-to-the-called-variants); **"Adding functional genomic annotations" only**

SNPeff will produce a modified `vcf` file and a HTML report. 

<div class="alert alert-warning">

**Discussion:** Scroll through the contents of the vcf file produced by snpeff. What extra information has it added? Try and locate the variants within `BRCA1`. Also take some time to digest the contents of the HTML report and the information it provides

</div>



## Annotation with Ensembl VEP

A useful alternative to running SNPeff within Galaxy is the online VEP tool provided by Ensembl. This will annotate our variants with gene identifiers and also provide some predictions about the impact of the variant. 

More documentation on Ensembl VEP is [available online](http://grch37.ensembl.org/info/docs/tools/vep/online/index.html)

Command line tools are available, but we will use the online interface; making sure that we access the version of VEP with the correct genome version. Going straight to the Ensembl VEP website will mean using a later genome build.

The **hg19** version of VEP can be accessed [here](http://grch37.ensembl.org/Homo_sapiens/Tools/VEP). A set of coordinates can be entered into the text box, or a VCF file can be uploaded.

![](media/vep-upload.png)

<div class="alert alert-warning">
Upload the `vcf` file that you annotated with SNPeff. If you were unable to complete this step, a copy is available in the google drive; `231335_231336_VarScan_Variants_SnpEff_SS2.vcf`.
</div>

You will have a choice about what transcript database to use. The output can also be configured by clicking the *+* symbol next to a particular section. e.g. *Variants and frequency data*. After selecting the options you want, scroll down to the bottom of the page and click **Run**. The screen should now change to let you know that VEP is running.

![](media/vep-running.png)

The screen will refresh by itself, and eventually a green *Done* box should appear. At which point you will be able to inspect the results

![](media/vep-finished.png)

The results can be inspected online, or downloaded. Downloading as a text file is better for browsing in Excel, and can also be manipulated in languages such as R.

# Variant Calling for Matched Normal Samples

[Click here](somatic_snv_assessment_exercise.html) to follow an exercise on inspecting and evaluating somatic calls
